########################################################################################################################
#################### Docker environment related variables ##############################################################
########################################################################################################################
PYTHON_IMAGE_VERSION=3.12.6-slim-bullseye
LLM_MODEL_IMAGE=ai/smollm2:360M-Q4_K_M
########################################################################################################################

LOG_LEVEL=INFO
PORT=8050

# model settings
LLM_MODE=ai/smollm2
LLM_BASE_URL=http://model-runner.docker.internal/engines/llama.cpp/v1/chat/completions
